# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dDiCdp-XzcsH4b5wRddOM1_Aj_S70Fwz
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import folium
from streamlit_folium import st_folium
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from ortools.constraint_solver import routing_enums_pb2
from ortools.constraint_solver import pywrapcp

# --- Page Configuration ---
st.set_page_config(page_title="Smart Bin Analytics", layout="wide")

# --- Load and Cache Data ---
@st.cache_data
def load_data():
    try:
        df = pd.read_csv('data.csv')
    except FileNotFoundError:
        st.error("Error: 'data.csv' not found. Using dummy data.")
        # Create a dummy DataFrame to prevent script crash
        df = pd.DataFrame({
            'timestamp': pd.to_datetime(['2025-01-01 10:00:00']),
            'bin_id': ['B101'],
            'hour_of_day': [10],
            'day_of_week': ['Monday'],
            'ward': ['Ward_A'],
            'area_type': ['Residential'],
            'time_since_last_pickup': [24],
            'bin_fill_percent': [50],
            'bin_capacity_liters': [1000],
            'bin_location_lat': [19.0760],
            'bin_location_lon': [72.8777]
        })
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
    return df

df = load_data()

# --- Sidebar Navigation ---
st.sidebar.title("Navigation")
# FIX: Added "Impact & Financial Analysis" to the list below
page = st.sidebar.radio("Go to", ["Home", "Exploratory Data Analysis", "Predictive Model", "Route Optimization", "Impact & Financial Analysis"])

# --- Home Page ---
if page == "Home":
    st.title("Smart Waste Management Analytics Dashboard")
    st.write("Welcome! This dashboard provides a comprehensive overview of the Smart Bin project's data science components.")
    st.subheader("Project Overview")
    st.write("""
    - *Live Data:* A physical prototype sends real-time fill-level data to a cloud dashboard.
    - *Historical Analysis:* We analyze a large dataset to understand waste generation patterns.
    - *Predictive Modeling:* A machine learning model forecasts when bins will become full.
    - *Route Optimization:* An algorithm calculates the most efficient collection route for full bins.
    - *Financial Impact:* A comprehensive model calculating ROI, carbon credits, and operational savings.
    """)
    st.subheader("Dataset at a Glance")
    st.dataframe(df.head())
    st.write(f"The dataset contains *{len(df)}* hourly readings from *{df['bin_id'].nunique()}* simulated smart bins.")

# --- EDA Page ---
elif page == "Exploratory Data Analysis":
    st.title("Exploratory Data Analysis (EDA)")
    st.write("These charts are now interactive. You can zoom, pan, and hover over the data.")

    st.subheader("Average Bin Fill Percentage by Hour of Day")
    hourly_fill_pattern = df.groupby(['hour_of_day', 'area_type'])['bin_fill_percent'].mean().reset_index()
    fig1 = px.line(hourly_fill_pattern,
                   x='hour_of_day',
                   y='bin_fill_percent',
                   color='area_type',
                   title='Average Bin Fill Percentage by Hour of Day',
                   labels={'hour_of_day': 'Hour of Day', 'bin_fill_percent': 'Average Fill Level (%)'})
    st.plotly_chart(fig1, use_container_width=True)

    st.subheader("Average Bin Fill Percentage by Day of the Week")
    daily_avg = df.groupby('day_of_week')['bin_fill_percent'].mean().reset_index()
    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    fig2 = px.bar(daily_avg,
                  x='day_of_week',
                  y='bin_fill_percent',
                  category_orders={"day_of_week": day_order},
                  title='Average Bin Fill Percentage by Day of the Week',
                  labels={'day_of_week': 'Day of the Week', 'bin_fill_percent': 'Average Fill Level (%)'})
    st.plotly_chart(fig2, use_container_width=True)

# --- Predictive Model Page ---
elif page == "Predictive Model":
    st.title("Predictive Model for Bin Fill Level")

    with st.spinner("Preparing data and training model..."):
        features_to_use = ['hour_of_day', 'day_of_week', 'ward', 'area_type', 'time_since_last_pickup']
        target_variable = 'bin_fill_percent'
        model_df = df[features_to_use + [target_variable]].copy()

        for feature in ['day_of_week', 'ward', 'area_type']:
            if feature in model_df.columns:
                 model_df = pd.get_dummies(model_df, columns=[feature], prefix=feature, drop_first=True)

        X = model_df.drop(target_variable, axis=1, errors='ignore')
        y = model_df[target_variable]

        if len(X) < 2:
            st.warning("Insufficient data to train the model after preprocessing.")
            mae, r2 = np.nan, np.nan
            predictions = pd.Series([0])
            y_test = pd.Series([0])
        else:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
            model.fit(X_train, y_train)
            predictions = model.predict(X_test)
            mae = mean_absolute_error(y_test, predictions)
            r2 = r2_score(y_test, predictions)

    st.subheader("Model Performance")
    col1, col2 = st.columns(2)
    col1.metric("Mean Absolute Error (MAE)", f"{mae:.2f}%")
    col2.metric("R-squared (RÂ²) Score", f"{r2:.2f}")

    st.subheader("Interactive Analysis of Model Predictions")

    if len(y_test) > 10:
        plot_data = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})
        plot_data['Error'] = abs(plot_data['Actual'] - plot_data['Predicted'])
        plot_data_sample = plot_data.sample(min(5000, len(plot_data)), random_state=42)

        fig = px.scatter(
            plot_data_sample,
            x='Actual',
            y='Predicted',
            color='Error',
            color_continuous_scale=px.colors.sequential.Viridis,
            marginal_x='histogram',
            marginal_y='histogram',
            hover_name=plot_data_sample.index,
            hover_data={'Actual': ':.2f', 'Predicted': ':.2f', 'Error': ':.2f'},
            title="Actual vs. Predicted Fill Levels (Colored by Prediction Error)",
            template='plotly_white'
        )

        fig.add_shape(type='line', x0=0, y0=0, x1=100, y1=100, line=dict(color='Red', width=2, dash='dash'))
        fig.update_layout(xaxis_title='Actual Fill Level (%)', yaxis_title='Predicted Fill Level (%)')
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("Not enough test data points to generate a meaningful scatter plot.")



# --- Impact & Financial Analysis Page (New Section) ---
elif page == "Impact & Financial Analysis":
    st.title("ðŸ’Ž Comprehensive Business & Impact Model")
    st.markdown("### The 360Â° Value Proposition")
    st.write("This advanced model evaluates the project's viability across four dimensions: *Operational Savings, **Revenue Generation, **Strategic Cost Avoidance, and **Environmental Monetization*.")

    # --- 1. THE CONTROL CENTER (Sidebar) ---
    st.sidebar.header("âš™ Simulation Parameters")

    # [TOGGLE] EV FLEET SWITCH
    is_ev = st.sidebar.checkbox("âš¡ Activate Electric Vehicle (EV) Fleet Mode")

    # A. CAPEX (One-time Investment)
    st.sidebar.subheader("1. CAPEX (Initial Investment)")
    num_trucks = st.sidebar.number_input("Fleet Size (Trucks)", value=5, min_value=1)
    hardware_cost_per_bin = st.sidebar.number_input("Hardware Cost/Bin (â‚¹)", value=1500)
    total_bins = st.sidebar.number_input("Total Smart Bins", value=100)
    software_dev_cost = st.sidebar.number_input("Software/Cloud Setup Cost (â‚¹)", value=50000)

    # B. OPEX (Recurring Costs)
    st.sidebar.subheader("2. OPEX (Operational)")
    driver_wage = st.sidebar.slider("Staff Hourly Wage (â‚¹)", 100, 500, 200)

    # Dynamic Fuel/Energy Inputs
    if is_ev:
        st.sidebar.markdown("--- *âš¡ EV Settings* ---")
        fuel_price = st.sidebar.number_input("Electricity Cost (â‚¹/kWh)", value=10.0)
        truck_efficiency = st.sidebar.number_input("EV Efficiency (km/kWh)", value=1.5)
        co2_factor = 0.82 # kg CO2 per kWh (Grid Average)
        fuel_label = "Electricity"
        fuel_unit = "kWh"
    else:
        st.sidebar.markdown("--- *â›½ Diesel Settings* ---")
        fuel_price = st.sidebar.number_input("Diesel Price (â‚¹/Liter)", value=104.0)
        truck_efficiency = st.sidebar.number_input("Truck Mileage (km/L)", value=4.0)
        co2_factor = 2.68 # kg CO2 per Liter
        fuel_label = "Fuel"
        fuel_unit = "L"

    # Maintenance & Connectivity
    maintenance_per_km = st.sidebar.number_input("Vehicle Maint. (â‚¹/km)", value=5.0)
    cloud_cost_per_bin = st.sidebar.number_input("Cloud/Data Cost per Bin/Month (â‚¹)", value=20) # SIM card/Cloud sub

    # C. REVENUE & AVOIDANCE (The "Hidden" Value)
    st.sidebar.subheader("3. Revenue & Strategic Value")

    # Recycling Revenue
    recyclable_value_per_kg = st.sidebar.number_input("Avg. Recyclable Value (â‚¹/kg)", value=15.0)
    recycling_rate_increase = st.sidebar.slider("Recycling Efficiency Boost (%)", 0, 50, 20)
    # (Assumption: Smart routing allows better segregation or cleaner pickup)
    daily_waste_collected_kg = st.sidebar.number_input("Total Daily Waste (kg)", value=2000.0)

    # Penalty Avoidance (SLA)
    penalty_per_overflow = st.sidebar.number_input("Fine per Overflowing Bin (â‚¹)", value=500)
    overflows_prevented_month = st.sidebar.slider("Overflows Prevented/Month", 0, 100, 25)

    # Carbon Credits
    carbon_credit_price = st.sidebar.number_input("Carbon Credit Price (â‚¹/Ton CO2)", value=1500.0)

    # D. ROUTE SCENARIOS
    st.sidebar.subheader("4. Logistics Efficiency")
    st.sidebar.markdown("ðŸ”´ Traditional (Fixed)")
    dist_old = st.sidebar.number_input("Daily Dist. Fixed (km)", value=60.0)
    trips_old = st.sidebar.slider("Trips/Month (Fixed)", 15, 30, 30)
    hours_old = st.sidebar.number_input("Hours/Trip (Fixed)", value=7.0)

    st.sidebar.markdown("ðŸŸ¢ Smart (Optimized)")
    dist_new = st.sidebar.number_input("Daily Dist. Smart (km)", value=40.0)
    trips_new = st.sidebar.slider("Trips/Month (Smart)", 15, 30, 24)
    hours_new = st.sidebar.number_input("Hours/Trip (Smart)", value=5.0)

    # --- 2. THE CALCULATION ENGINE ---

    # CAPEX
    total_capex = (hardware_cost_per_bin * total_bins) + software_dev_cost

    # Function to calculate Core OPEX
    def calc_opex(dist, trips, hours):
        total_dist = dist * trips * num_trucks
        total_hours = hours * trips * num_trucks

        energy_consumed = total_dist / truck_efficiency
        energy_cost = energy_consumed * fuel_price

        labor_cost = total_hours * driver_wage
        maint_cost = total_dist * maintenance_per_km

        # Cloud costs (only applies to Smart System really, but added for completeness)

        co2_kg = energy_consumed * co2_factor

        return {
            "energy": energy_cost,
            "labor": labor_cost,
            "maint": maint_cost,
            "total_opex": energy_cost + labor_cost + maint_cost,
            "co2": co2_kg,
            "dist": total_dist
        }

    old = calc_opex(dist_old, trips_old, hours_old)
    new = calc_opex(dist_new, trips_new, hours_new)

    # Add Cloud Cost to Smart System OPEX
    smart_cloud_cost = cloud_cost_per_bin * total_bins
    new["total_opex"] += smart_cloud_cost

    # --- SAVINGS & REVENUE CALCULATIONS ---

    # 1. Direct Operational Savings
    opex_savings = old["total_opex"] - new["total_opex"]

    # 2. Revenue from Recyclables (Incremental)
    # Assumption: Smart system improves segregation/collection efficiency by X%
    base_revenue = daily_waste_collected_kg * 30 * recyclable_value_per_kg * 0.1 # Assuming 10% base recycling rate
    improved_revenue = daily_waste_collected_kg * 30 * recyclable_value_per_kg * (0.1 + (recycling_rate_increase/100))
    revenue_gain = improved_revenue - base_revenue

    # 3. Cost Avoidance (Penalties)
    penalty_savings = overflows_prevented_month * penalty_per_overflow

    # 4. Environmental Monetization
    co2_saved_tons = (old["co2"] - new["co2"]) / 1000
    carbon_credit_revenue = co2_saved_tons * carbon_credit_price

    # TOTAL MONTHLY BENEFIT
    total_monthly_benefit = opex_savings + revenue_gain + penalty_savings + carbon_credit_revenue

    # ROI
    months_breakeven = total_capex / total_monthly_benefit if total_monthly_benefit > 0 else 0

    # --- 3. VISUALIZATION DASHBOARD ---

    # KPI ROW
    st.markdown("### ðŸ“Š Monthly Financial Snapshot")
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("Net Monthly Benefit", f"â‚¹{total_monthly_benefit:,.0f}", help="Savings + Revenue + Avoided Fines")
    k2.metric("Direct OPEX Savings", f"â‚¹{opex_savings:,.0f}", delta="Fuel & Labor")
    k3.metric("Revenue & Avoidance", f"â‚¹{revenue_gain + penalty_savings:,.0f}", delta="New Value Stream")
    k4.metric("ROI Break-even", f"{months_breakeven:.1f} Months", delta_color="off")

    st.markdown("---")

    # DETAILED BREAKDOWN
    c1, c2 = st.columns([2, 1])

    with c1:
        st.subheader("Waterfall: Where is the Value coming from?")
        waterfall_data = pd.DataFrame({
            "Source": ["Operational Savings", "Recycling Revenue", "Avoided Penalties", "Carbon Credits"],
            "Amount (â‚¹)": [opex_savings, revenue_gain, penalty_savings, carbon_credit_revenue]
        })
        fig_water = px.bar(waterfall_data, x="Source", y="Amount (â‚¹)", color="Source",
                           title="Monthly Value Components", text_auto='.2s')
        st.plotly_chart(fig_water, use_container_width=True)

    with c2:
        st.subheader("Environmental Impact")
        st.metric("CO2 Prevented", f"{co2_saved_tons*1000:,.0f} kg")
        st.metric("Carbon Credit Value", f"â‚¹{carbon_credit_revenue:,.2f}")
        st.info(f"Equivalent to planting *{int(co2_saved_tons * 1000 / 20)} trees* per month.")

    # CUMULATIVE CASH FLOW (The Investor View)
    st.subheader("ðŸ“ˆ 3-Year Financial Projection")

    years = 3
    months_range = range(1, (years * 12) + 1)
    cash_flow = []
    current_balance = -total_capex # Start in debt (CAPEX)

    for m in months_range:
        current_balance += total_monthly_benefit
        cash_flow.append(current_balance)

    df_cf = pd.DataFrame({"Month": list(months_range), "Net Cash Flow": cash_flow})

    fig_cf = px.line(df_cf, x="Month", y="Net Cash Flow", title="Cumulative Cash Flow (NPV Proxy)", markers=False)
    fig_cf.add_hline(y=0, line_dash="dash", line_color="green", annotation_text="Break-even")
    fig_cf.add_vrect(x0=0, x1=months_breakeven, fillcolor="red", opacity=0.1, annotation_text="Investment Phase")
    fig_cf.add_vrect(x0=months_breakeven, x1=36, fillcolor="green", opacity=0.1, annotation_text="Profit Phase")

    st.plotly_chart(fig_cf, use_container_width=True)

    st.success(f"""
    *Final Verdict:* This project is not just a cost-saver; it is a revenue generator.
    By integrating *Recycling Revenue* (â‚¹{revenue_gain:,.0f}/mo) and *Penalty Avoidance* (â‚¹{penalty_savings:,.0f}/mo) with standard operational savings,
    the system pays for its hardware in *{months_breakeven:.1f} months*, creating a sustainable profit model for the municipality.
    """)
    import streamlit as st
import pandas as pd
import osmnx as ox
import networkx as nx
import folium
from streamlit_folium import st_folium
import qrcode
from io import BytesIO
import os

# --- 1. SETTINGS ---
st.set_page_config(page_title="Smart Waste AI Mission Control", layout="wide")

GARAGES = {
    "Truck 1 (Worli)": (19.0178, 72.8478),
    "Truck 2 (Bandra)": (19.0596, 72.8295),
    "Truck 3 (Andheri)": (19.1136, 72.8697),
    "Truck 4 (Kurla)": (19.0726, 72.8844),
    "Truck 5 (Borivali)": (19.2307, 72.8567)
}
DEONAR_DUMPING = (19.0550, 72.9250)

@st.cache_data
def load_data():
    all_files = [f for f in os.listdir('.') if f.endswith('.csv')]
    target = 'data.csv' if 'data.csv' in all_files else (all_files[0] if all_files else None)
    if not target: return None
    try:
        df = pd.read_csv(target, sep=None, engine='python', encoding='utf-8-sig')
        df.columns = [c.strip().lower() for c in df.columns]

        # --- THE FIX: Standardize BIN_ID and others ---
        rename_dict = {
            'bin_location_lat': 'lat', 'bin_location_lon': 'lon',
            'bin_fill_percent': 'fill', 'timestamp': 'timestamp',
            'bin_id': 'bin_id', 'bin id': 'bin_id', 'id': 'bin_id'
        }
        for old, new in rename_dict.items():
            for col in df.columns:
                if old == col:
                    df = df.rename(columns={col: new})

        df['timestamp'] = pd.to_datetime(df['timestamp'], dayfirst=True, errors='coerce')
        return df.dropna(subset=['timestamp'])
    except: return None

def get_dist(p1, p2):
    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5

@st.cache_resource
def get_map():
    return ox.graph_from_point((19.0760, 72.8777), dist=8000, network_type='drive')

# --- 2. EXECUTION ---
st.title("ðŸš› AI Multi-Fleet Mission Control")
df = load_data()

if df is not None:
    # Sidebar
    st.sidebar.header("ðŸ•¹ Dispatch Controls")
    selected_truck = st.sidebar.selectbox("Select Active Truck", list(GARAGES.keys()))
    threshold = st.sidebar.slider("Fill Threshold (%)", 0, 100, 75)

    # Simulation Slider
    times = sorted(df['timestamp'].unique())
    default_time = times[int(len(times)*0.85)]
    sim_time = st.sidebar.select_slider("Select Time", options=times, value=default_time)

    df_snap = df[df['timestamp'] == sim_time].copy()

    # Assignment logic
    def assign_truck(row):
        loc = (row['lat'], row['lon'])
        dists = {name: get_dist(loc, coords) for name, coords in GARAGES.items()}
        return min(dists, key=dists.get)

    df_snap['assigned_truck'] = df_snap.apply(assign_truck, axis=1)

    # Filter bins for selected truck
    all_my_bins = df_snap[(df_snap['assigned_truck'] == selected_truck) & (df_snap['fill'] >= threshold)]
    all_my_bins = all_my_bins.sort_values('fill', ascending=False)

    # Multi-Trip Pipeline
    st.sidebar.markdown("---")
    st.sidebar.subheader("ðŸ“¦ Trip Pipeline")
    bins_per_trip = 8
    total_pending = len(all_my_bins)
    num_trips = (total_pending // bins_per_trip) + (1 if total_pending % bins_per_trip > 0 else 0)

    if num_trips > 0:
        trip_num = st.sidebar.selectbox(f"Select Trip (Total: {num_trips})",
                                        range(1, num_trips + 1),
                                        format_func=lambda x: f"Trip {x}")
        start_idx = (trip_num - 1) * bins_per_trip
        current_mission_bins = all_my_bins.iloc[start_idx : start_idx + bins_per_trip]
    else:
        current_mission_bins = pd.DataFrame()

    # Metrics
    c1, c2, c3 = st.columns(3)
    c1.metric("Vehicle", selected_truck)
    c2.metric("Total Bins for Truck", total_pending)
    c3.metric("Current Trip Stops", len(current_mission_bins))

    # --- 3. MAP ---
    try:
        G = get_map()
        m = folium.Map(location=[19.0760, 72.8777], zoom_start=12, tiles="CartoDB positron")

        # Plot Bins
        for _, row in df_snap.iterrows():
            is_full = row['fill'] >= threshold
            is_mine = row['assigned_truck'] == selected_truck

            # Check if this bin is in the current trip (handle missing bin_id gracefully)
            is_in_current = False
            if not current_mission_bins.empty and 'bin_id' in row:
                is_in_current = row['bin_id'] in current_mission_bins['bin_id'].values

            if is_full and is_mine and is_in_current: color = 'red'
            elif is_full and is_mine and not is_in_current: color = 'blue'
            elif is_full and not is_mine: color = 'orange'
            else: color = 'green'

            folium.Marker([row['lat'], row['lon']],
                          icon=folium.Icon(color=color, icon='trash', prefix='fa')).add_to(m)

        # Draw Current Route
        garage_loc = GARAGES[selected_truck]
        if not current_mission_bins.empty:
            pts = [garage_loc] + list(zip(current_mission_bins['lat'], current_mission_bins['lon'])) + [DEONAR_DUMPING]
            path_coords = []
            for i in range(len(pts)-1):
                try:
                    n1 = ox.nearest_nodes(G, pts[i][1], pts[i][0])
                    n2 = ox.nearest_nodes(G, pts[i+1][1], pts[i+1][0])
                    route = nx.shortest_path(G, n1, n2, weight='length')
                    path_coords.extend([[G.nodes[node]['y'], G.nodes[node]['x']] for node in route])
                except:
                    path_coords.append([pts[i][0], pts[i][1]])
                    path_coords.append([pts[i+1][0], pts[i+1][1]])

            if path_coords:
                folium.PolyLine(path_coords, color="#3498db", weight=6, opacity=0.8).add_to(m)

        folium.Marker(garage_loc, icon=folium.Icon(color='blue', icon='truck', prefix='fa')).add_to(m)
        folium.Marker(DEONAR_DUMPING, icon=folium.Icon(color='black', icon='home', prefix='fa')).add_to(m)

        st_folium(m, width=1200, height=550, key="mission_map")

        # --- 4. QR CODE ---
        if not current_mission_bins.empty:
            st.subheader(f"ðŸ“² Driver QR: Trip {trip_num}")
            google_url = f"https://www.google.com/maps/dir/?api=1&origin={garage_loc[0]},{garage_loc[1]}&destination={DEONAR_DUMPING[0]},{DEONAR_DUMPING[1]}&waypoints=" + "|".join([f"{lat},{lon}" for lat, lon in zip(current_mission_bins['lat'], current_mission_bins['lon'])]) + "&travelmode=driving"

            q_col, t_col = st.columns([1, 4])
            with q_col:
                qr = qrcode.make(google_url)
                buf = BytesIO()
                qr.save(buf)
                st.image(buf, width=200)
            with t_col:
                st.success(f"Trip {trip_num} ready for Driver Dispatch.")
                st.info("The Blue markers on the map represent the bins queued for the next trip!")

    except Exception as e:
        st.error(f"Mapping Error: {e}")
else:
    st.error("Missing Data: Please ensure 'data.csv' is uploaded.")
import streamlit as st
import pandas as pd
import folium
from streamlit_folium import st_folium

# --- 1. PAGE CONFIGURATION ---
st.set_page_config(page_title="Smart Bin AI Dashboard", layout="wide")

# Custom CSS to make Streamlit look like a high-end BI tool
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    div[data-testid="metric-container"] {
        background-color: #ffffff;
        border: 1px solid #dee2e6;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. DATA LOADING ---
@st.cache_data
def load_csv():
    try:
        df = pd.read_csv('data.csv')
        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
        return df
    except:
        return pd.DataFrame() # Returns empty if file not found

df = load_csv()

# --- 3. THE SIDEBAR (Slicers) ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3299/3299935.png", width=100)
    st.title("Control Panel")
    st.markdown("---")
    
    if not df.empty:
        # Filter by Bin ID
        selected_bins = st.multiselect("Select Bins", options=df['bin_id'].unique(), default=df['bin_id'].unique())
        # Filter by Fill Level
        fill_range = st.slider("Fill Level Range (%)", 0, 100, (0, 100))
        
        filtered_df = df[(df['bin_id'].isin(selected_bins)) & 
                         (df['bin_fill_percent'] >= fill_range[0]) & 
                         (df['bin_fill_percent'] <= fill_range[1])]
    else:
        st.error("No CSV data found on GitHub.")

# --- 4. MAIN INTERFACE ---
st.title("ðŸš› Smart City: Waste Management Intelligence")

# Use Tabs to separate Python Logic and Power BI
tab1, tab2 = st.tabs(["ðŸ“Š Live IoT Analytics", "ðŸ“ˆ Detailed Power BI Report"])

with tab1:
    if not df.empty:
        # --- TOP ROW: KPI CARDS ---
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("Active Bins", len(filtered_df))
        m2.metric("Avg Fill", f"{filtered_df['bin_fill_percent'].mean():.1f}%")
        m3.metric("Critical (80%+)", len(filtered_df[filtered_df['bin_fill_percent'] >= 80]))
        m4.metric("Last Sync", df['timestamp'].max().strftime('%H:%M'))

        st.markdown("---")

        # --- MIDDLE ROW: MAP AND CHART ---
        col_left, col_right = st.columns([2, 1])

        with col_left:
            st.subheader("ðŸ“ Real-time GPS Tracking")
            # Map centered on data
            avg_lat, avg_lon = filtered_df['bin_location_lat'].mean(), filtered_df['bin_location_lon'].mean()
            m = folium.Map(location=[avg_lat, avg_lon], zoom_start=13, tiles="cartodbpositron")
            
            for _, row in filtered_df.iterrows():
                color = 'red' if row['bin_fill_percent'] >= 80 else 'green'
                folium.Marker(
                    [row['bin_location_lat'], row['bin_location_lon']],
                    popup=f"ID: {row['bin_id']} | Fill: {row['bin_fill_percent']}%",
                    icon=folium.Icon(color=color, icon='trash', prefix='fa')
                ).add_to(m)
            
            st_folium(m, width="100%", height=500)

        with col_right:
            st.subheader("ðŸ“Š Fill Level by Bin")
            st.bar_chart(filtered_df.set_index('bin_id')['bin_fill_percent'])
            st.subheader("ðŸ“‹ Priority List")
            st.dataframe(filtered_df[['bin_id', 'bin_fill_percent']].sort_values('bin_fill_percent', ascending=False), hide_index=True)

with tab2:
    st.subheader("External Power BI Integration")
    # Replace the link below with your "Publish to Web" Power BI link
    pbi_url = "https://app.powerbi.com/links/PQ2P41cZAi?ctid=c290ab75-f93e-4848-8b0b-550dd7acfc33&pbi_source=linkShare "
    
    if "YOUR_PBI_EMBED_LINK" in pbi_url:
        st.info("ðŸ’¡ To show your Power BI report here, paste your 'Publish to Web' link into the code.")
    
    st.components.v1.iframe(pbi_url, height=800, scrolling=True)
